{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Model Selection</center></h1>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will see, which model will perform better on given dataset. In the last notebook, we saw which dataset is the most unbiased and from now on we will work with it. I already wrote a script that will get us train and test for our X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"notebook_helper_functions/models\")\n",
    "import set_jupyter_path\n",
    "from src.car_price_prediction.utils import df_utils,dataset_manager\n",
    "from linear_regression_model import LinearRegressionModel\n",
    "from random_forest_model import RandomForestModel\n",
    "from svm_model import SVMModel\n",
    "from bagging_model import BaggingModel\n",
    "from lasso_regression_model import LassoRegressionModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_manager.get_processed_dataset()\n",
    "X,y = df_utils.get_data_and_target(df)\n",
    "X_std = df_utils.scale_train(X)\n",
    "X = pd.get_dummies(X)\n",
    "X_std = pd.get_dummies(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for Linear Regression: -6647.573'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegressionModel(\"Linear Regression\")\n",
    "lr.cv_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for Random Forest: -2246.447'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestModel(\"Random Forest\",n_estimators=30)\n",
    "forest.cv_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for Gaussian Kernel: -11388.312'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussianSVM = SVMModel(\"Gaussian Kernel\",kernel = 'rbf')\n",
    "gaussianSVM.cv_score(X_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for Linear Kernel: -7107.966'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVM = SVMModel(\"Linear Kernel\",kernel = 'linear')\n",
    "linearSVM.cv_score(X_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for Bootstrap Aggregating: -2231.610'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingModel('Bootstrap Aggregating')\n",
    "bagging.cv_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CV MAE score for LASSO regression: -6630.575'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoRegressionModel(\"LASSO regression\")\n",
    "lasso.cv_score(X_std,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best models are Random Forest Regressor and Bagging Regressor. Looking at their errors, I can say, that they probably have same mistakes. Making ensemble of them maybe will help, but not much, and the efficiency will be decreased for sure. So now I will try to choose between Random Forest Regressor and Bagging Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
